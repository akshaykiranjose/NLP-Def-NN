{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neural translation model\n",
    "### English to Deutsch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:35.825861Z",
     "iopub.status.busy": "2022-06-29T06:48:35.825209Z",
     "iopub.status.idle": "2022-06-29T06:48:43.264566Z",
     "shell.execute_reply": "2022-06-29T06:48:43.263284Z",
     "shell.execute_reply.started": "2022-06-29T06:48:35.825727Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import unicodedata\n",
    "import re\n",
    "from IPython.display import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/germany_uk_flags.png\">\n",
    "\n",
    "Using a language dataset from http://www.manythings.org/anki/  of the dataset used is not part of the grading rubric.\n",
    "\n",
    "The goal is to develop a neural translation model from English to German, making use of a pre-trained English word embedding module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:43.268413Z",
     "iopub.status.busy": "2022-06-29T06:48:43.267492Z",
     "iopub.status.idle": "2022-06-29T06:48:43.678033Z",
     "shell.execute_reply": "2022-06-29T06:48:43.676787Z",
     "shell.execute_reply.started": "2022-06-29T06:48:43.268366Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "NUM_EXAMPLES = 20000\n",
    "data_examples = []\n",
    "with open('data/deu.txt', 'r', encoding='utf8') as f:\n",
    "    for line in f.readlines():\n",
    "        if len(data_examples) < NUM_EXAMPLES:\n",
    "            data_examples.append(line)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:43.680188Z",
     "iopub.status.busy": "2022-06-29T06:48:43.679724Z",
     "iopub.status.idle": "2022-06-29T06:48:43.690580Z",
     "shell.execute_reply": "2022-06-29T06:48:43.689099Z",
     "shell.execute_reply.started": "2022-06-29T06:48:43.680127Z"
    }
   },
   "outputs": [],
   "source": [
    "# These functions preprocess English and German sentences\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"ü\", 'ue', sentence)\n",
    "    sentence = re.sub(r\"ä\", 'ae', sentence)\n",
    "    sentence = re.sub(r\"ö\", 'oe', sentence)\n",
    "    sentence = re.sub(r'ß', 'ss', sentence)\n",
    "    \n",
    "    sentence = unicode_to_ascii(sentence)\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r\"[^a-z?.!,']+\", \" \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    return sentence.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The custom translation model\n",
    "<img src=\"data/neural_translation_model.png\">\n",
    "The following is a schematic of the custom translation model architecture you will develop in this project.\n",
    "\n",
    "The custom model consists of an encoder RNN and a decoder RNN. The encoder takes words of an English sentence as input, and uses a pre-trained word embedding to embed the words into a 128-dimensional space. To indicate the end of the input sentence, a special end token (in the same 128-dimensional space) is passed in as an input. This token is a TensorFlow Variable that is learned in the training phase (unlike the pre-trained word embedding, which is frozen).\n",
    "\n",
    "The decoder RNN takes the internal state of the encoder network as its initial state. A start token is passed in as the first input, which is embedded using a learned German word embedding. The decoder RNN then makes a prediction for the next German word, which during inference is then passed in as the following input, and this process is repeated until the special `<end>` token is emitted from the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:46.067990Z",
     "iopub.status.busy": "2022-06-29T06:48:46.067635Z",
     "iopub.status.idle": "2022-06-29T06:48:47.191180Z",
     "shell.execute_reply": "2022-06-29T06:48:47.189895Z",
     "shell.execute_reply.started": "2022-06-29T06:48:46.067945Z"
    }
   },
   "outputs": [],
   "source": [
    "# lists of both sequences\n",
    "eng = []\n",
    "deu = []\n",
    "for sente in data_examples:\n",
    "    en, de = re.split(\"\\t\", sente)[0:2]\n",
    "    eng.append(preprocess_sentence(en))\n",
    "    deu.append(''.join(['<start> ', preprocess_sentence(de), ' <end>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:47.193949Z",
     "iopub.status.busy": "2022-06-29T06:48:47.193173Z",
     "iopub.status.idle": "2022-06-29T06:48:47.419678Z",
     "shell.execute_reply": "2022-06-29T06:48:47.418414Z",
     "shell.execute_reply.started": "2022-06-29T06:48:47.193900Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(deu)\n",
    "tokenizer_config = tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:47.422107Z",
     "iopub.status.busy": "2022-06-29T06:48:47.421668Z",
     "iopub.status.idle": "2022-06-29T06:48:47.428878Z",
     "shell.execute_reply": "2022-06-29T06:48:47.427564Z",
     "shell.execute_reply.started": "2022-06-29T06:48:47.422062Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer_config['word_index']\n",
    "index_word = tokenizer_config['index_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:47.431889Z",
     "iopub.status.busy": "2022-06-29T06:48:47.430871Z",
     "iopub.status.idle": "2022-06-29T06:48:47.774124Z",
     "shell.execute_reply": "2022-06-29T06:48:47.772806Z",
     "shell.execute_reply.started": "2022-06-29T06:48:47.431843Z"
    }
   },
   "outputs": [],
   "source": [
    "deu_tokenized = tokenizer.texts_to_sequences(deu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:47.791870Z",
     "iopub.status.busy": "2022-06-29T06:48:47.790734Z",
     "iopub.status.idle": "2022-06-29T06:48:47.802682Z",
     "shell.execute_reply": "2022-06-29T06:48:47.801196Z",
     "shell.execute_reply.started": "2022-06-29T06:48:47.791825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:           keep tom there .\n",
      "Deutsch:           <start> halte tom dort . <end>\n",
      "Deutsch Tokenized: [1, 288, 5, 141, 3, 2]\n",
      "English:           tom told a joke .\n",
      "Deutsch:           <start> tom hat einen witz erzaehlt . <end>\n",
      "Deutsch Tokenized: [1, 5, 16, 40, 469, 757, 3, 2]\n",
      "English:           you look healthy .\n",
      "Deutsch:           <start> du siehst gesund aus . <end>\n",
      "Deutsch Tokenized: [1, 13, 236, 700, 41, 3, 2]\n",
      "English:           i'll pay later .\n",
      "Deutsch:           <start> ich werde spaeter bezahlen . <end>\n",
      "Deutsch Tokenized: [1, 4, 39, 613, 464, 3, 2]\n",
      "English:           tom is a fool .\n",
      "Deutsch:           <start> tom ist ein narr . <end>\n",
      "Deutsch Tokenized: [1, 5, 6, 19, 1626, 3, 2]\n",
      "English:           tom surprised me .\n",
      "Deutsch:           <start> tom ueberraschte mich . <end>\n",
      "Deutsch Tokenized: [1, 5, 3083, 22, 3, 2]\n",
      "English:           i'm happy .\n",
      "Deutsch:           <start> ich bin froh . <end>\n",
      "Deutsch Tokenized: [1, 4, 15, 804, 3, 2]\n",
      "English:           i fainted .\n",
      "Deutsch:           <start> ich wurde ohnmaechtig . <end>\n",
      "Deutsch Tokenized: [1, 4, 68, 890, 3, 2]\n",
      "English:           tom was detained .\n",
      "Deutsch:           <start> tom wurde eingesperrt . <end>\n",
      "Deutsch Tokenized: [1, 5, 68, 3119, 3, 2]\n",
      "English:           it's pointless .\n",
      "Deutsch:           <start> es hat keinen sinn . <end>\n",
      "Deutsch Tokenized: [1, 10, 16, 223, 967, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "for _ in np.random.randint(len(data_examples), size=10):\n",
    "    print(\"English:           {}\\nDeutsch:           {}\\nDeutsch Tokenized: {}\".format(eng[_], deu[_], deu_tokenized[_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:47.806657Z",
     "iopub.status.busy": "2022-06-29T06:48:47.805489Z",
     "iopub.status.idle": "2022-06-29T06:48:47.908309Z",
     "shell.execute_reply": "2022-06-29T06:48:47.906848Z",
     "shell.execute_reply.started": "2022-06-29T06:48:47.806610Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "deu_tokenized_padded = pad_sequences(deu_tokenized,\n",
    "                                     maxlen=None,\n",
    "                                     padding='post',\n",
    "                                     value=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the data with tf.data.Dataset objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the embedding layer\n",
    "Download the module from [here](https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the pre-trained embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:48:47.910816Z",
     "iopub.status.busy": "2022-06-29T06:48:47.910313Z",
     "iopub.status.idle": "2022-06-29T06:49:03.144966Z",
     "shell.execute_reply": "2022-06-29T06:49:03.143730Z",
     "shell.execute_reply.started": "2022-06-29T06:48:47.910770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load embedding module from Tensorflow Hub\n",
    "embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1\", \n",
    "                                 output_shape=[128], input_shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:03.147439Z",
     "iopub.status.busy": "2022-06-29T06:49:03.146980Z",
     "iopub.status.idle": "2022-06-29T06:49:03.242662Z",
     "shell.execute_reply": "2022-06-29T06:49:03.241284Z",
     "shell.execute_reply.started": "2022-06-29T06:49:03.147393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 128), dtype=float32, numpy=\n",
       "array([[-0.33764157, -0.12379622,  0.00591127, ...,  0.11612329,\n",
       "         0.00694278, -0.11781787],\n",
       "       [ 0.15317006, -0.06145132,  0.07350554, ..., -0.15094818,\n",
       "        -0.12576084, -0.12233189],\n",
       "       [ 0.140084  ,  0.02941015,  0.04331429, ...,  0.0944555 ,\n",
       "        -0.1265336 , -0.25905257],\n",
       "       ...,\n",
       "       [ 0.03285561,  0.06345107, -0.05201129, ..., -0.08083786,\n",
       "        -0.10174342,  0.03802322],\n",
       "       [ 0.25726095,  0.01382531, -0.03725627, ..., -0.01149414,\n",
       "         0.0629049 , -0.00084706],\n",
       "       [-0.15089144,  0.276619  , -0.22944725, ...,  0.19615449,\n",
       "        -0.1152845 , -0.13853867]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the layer\n",
    "embedding_layer(tf.constant([\"<start>\", \"these\", \"aren't\", \"the\", \"droids\", \"you're\", \"looking\", \"for\", \"<end>\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:03.245079Z",
     "iopub.status.busy": "2022-06-29T06:49:03.244736Z",
     "iopub.status.idle": "2022-06-29T06:49:05.444705Z",
     "shell.execute_reply": "2022-06-29T06:49:05.443412Z",
     "shell.execute_reply.started": "2022-06-29T06:49:03.245049Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:05.446719Z",
     "iopub.status.busy": "2022-06-29T06:49:05.446304Z",
     "iopub.status.idle": "2022-06-29T06:49:05.463293Z",
     "shell.execute_reply": "2022-06-29T06:49:05.461909Z",
     "shell.execute_reply.started": "2022-06-29T06:49:05.446675Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(eng, deu_tokenized_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:05.466460Z",
     "iopub.status.busy": "2022-06-29T06:49:05.464941Z",
     "iopub.status.idle": "2022-06-29T06:49:05.553145Z",
     "shell.execute_reply": "2022-06-29T06:49:05.551905Z",
     "shell.execute_reply.started": "2022-06-29T06:49:05.466412Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:05.555635Z",
     "iopub.status.busy": "2022-06-29T06:49:05.555141Z",
     "iopub.status.idle": "2022-06-29T06:49:05.693245Z",
     "shell.execute_reply": "2022-06-29T06:49:05.691974Z",
     "shell.execute_reply.started": "2022-06-29T06:49:05.555592Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_eng(x,y):\n",
    "    x = tf.strings.split(x, sep=' ')\n",
    "    return x, y\n",
    "\n",
    "train_dataset = train_dataset.map(split_eng)\n",
    "test_dataset = test_dataset.map(split_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:05.695841Z",
     "iopub.status.busy": "2022-06-29T06:49:05.695340Z",
     "iopub.status.idle": "2022-06-29T06:49:06.291089Z",
     "shell.execute_reply": "2022-06-29T06:49:06.289859Z",
     "shell.execute_reply.started": "2022-06-29T06:49:05.695795Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_eng(x,y):\n",
    "    return embedding_layer(x), y\n",
    "\n",
    "train_dataset = train_dataset.map(embed_eng)\n",
    "test_dataset = test_dataset.map(embed_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:06.294046Z",
     "iopub.status.busy": "2022-06-29T06:49:06.293086Z",
     "iopub.status.idle": "2022-06-29T06:49:06.360552Z",
     "shell.execute_reply": "2022-06-29T06:49:06.359281Z",
     "shell.execute_reply.started": "2022-06-29T06:49:06.293982Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.filter(lambda x,y: tf.shape(x)[0] <= 13) \n",
    "test_dataset = test_dataset.filter(lambda x,y: tf.shape(x)[0] <= 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:06.363191Z",
     "iopub.status.busy": "2022-06-29T06:49:06.362722Z",
     "iopub.status.idle": "2022-06-29T06:49:06.372314Z",
     "shell.execute_reply": "2022-06-29T06:49:06.370923Z",
     "shell.execute_reply.started": "2022-06-29T06:49:06.363145Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad(x, y):\n",
    "    paddings = tf.concat(([[13-tf.shape(x)[0],0]], [[0,0]]), axis=0)\n",
    "    x = tf.pad(x, paddings)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:06.375159Z",
     "iopub.status.busy": "2022-06-29T06:49:06.374264Z",
     "iopub.status.idle": "2022-06-29T06:49:06.504376Z",
     "shell.execute_reply": "2022-06-29T06:49:06.502562Z",
     "shell.execute_reply.started": "2022-06-29T06:49:06.375112Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda x, y: (pad(x,y)))\n",
    "test_dataset = test_dataset.map(lambda x, y: (pad(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:06.506463Z",
     "iopub.status.busy": "2022-06-29T06:49:06.505977Z",
     "iopub.status.idle": "2022-06-29T06:49:06.515185Z",
     "shell.execute_reply": "2022-06-29T06:49:06.513788Z",
     "shell.execute_reply.started": "2022-06-29T06:49:06.506417Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(16)\n",
    "test_dataset = test_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:06.518797Z",
     "iopub.status.busy": "2022-06-29T06:49:06.517102Z",
     "iopub.status.idle": "2022-06-29T06:49:06.527957Z",
     "shell.execute_reply": "2022-06-29T06:49:06.526402Z",
     "shell.execute_reply.started": "2022-06-29T06:49:06.518748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, None, None), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 14), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:06.531078Z",
     "iopub.status.busy": "2022-06-29T06:49:06.530166Z",
     "iopub.status.idle": "2022-06-29T06:49:06.735036Z",
     "shell.execute_reply": "2022-06-29T06:49:06.733652Z",
     "shell.execute_reply.started": "2022-06-29T06:49:06.531033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 13, 128)\n",
      "tf.Tensor(\n",
      "[[   1  356  193    6    5    3    2    0    0    0    0    0    0    0]\n",
      " [   1 1539   55 2990    9    2    0    0    0    0    0    0    0    0]\n",
      " [   1  131    8   34  143    3    2    0    0    0    0    0    0    0]\n",
      " [   1   38   18    4 1437    7    2    0    0    0    0    0    0    0]\n",
      " [   1    5    6 1061 1289    3    2    0    0    0    0    0    0    0]\n",
      " [   1 1683   52   11  637    3    2    0    0    0    0    0    0    0]\n",
      " [   1   14   24   42 2665    3    2    0    0    0    0    0    0    0]\n",
      " [   1    8   69   10 3474    3    2    0    0    0    0    0    0    0]\n",
      " [   1    5    6  668    3    2    0    0    0    0    0    0    0    0]\n",
      " [   1    5  311   42 5303   63    3    2    0    0    0    0    0    0]\n",
      " [   1 3211   27    3    2    0    0    0    0    0    0    0    0    0]\n",
      " [   1    5   16   37  163  116    3    2    0    0    0    0    0    0]\n",
      " [   1  317    8   21  202  204    9    2    0    0    0    0    0    0]\n",
      " [   1   73   27 1417    7    2    0    0    0    0    0    0    0    0]\n",
      " [   1  412   28  164    9    2    0    0    0    0    0    0    0    0]\n",
      " [   1   26   23   12   49    3    2    0    0    0    0    0    0    0]], shape=(16, 14), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataset.take(1):\n",
    "    pass\n",
    "\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the custom layer\n",
    "You will now create a custom layer to add the learned end token embedding to the encoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:06.737891Z",
     "iopub.status.busy": "2022-06-29T06:49:06.737382Z",
     "iopub.status.idle": "2022-06-29T06:49:06.750098Z",
     "shell.execute_reply": "2022-06-29T06:49:06.748384Z",
     "shell.execute_reply.started": "2022-06-29T06:49:06.737843Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "class EmbedEndToken(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EmbedEndToken, self).__init__(**kwargs)\n",
    "        self.end_token_embed = tf.Variable(initial_value=tf.random.uniform(shape=(128,)), trainable=True)\n",
    "\n",
    "    def call(self, inputs): #inputs is of shape (16,13,128)\n",
    "        end_token = tf.tile(\n",
    "                tf.reshape(self.end_token_embed, shape=(1, 1, self.end_token_embed.shape[0])),\n",
    "                [tf.shape(inputs)[0], 1, 1])\n",
    "        return tf.keras.layers.concatenate([inputs, end_token], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:06.761542Z",
     "iopub.status.busy": "2022-06-29T06:49:06.761177Z",
     "iopub.status.idle": "2022-06-29T06:49:06.917439Z",
     "shell.execute_reply": "2022-06-29T06:49:06.915921Z",
     "shell.execute_reply.started": "2022-06-29T06:49:06.761512Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 13, 128)\n",
      "(16, 14, 128)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataset.take(1):\n",
    "  #print(x[0])\n",
    "      print(x.shape) #(16, 13, 128)\n",
    "      print(EmbedEndToken()(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the encoder network\n",
    "\n",
    "<img src=\"data/neural_translation_model_encoder.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:06.920123Z",
     "iopub.status.busy": "2022-06-29T06:49:06.919697Z",
     "iopub.status.idle": "2022-06-29T06:49:08.110845Z",
     "shell.execute_reply": "2022-06-29T06:49:08.109517Z",
     "shell.execute_reply.started": "2022-06-29T06:49:06.920078Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=((13,128)))\n",
    "h = EmbedEndToken()(inputs)\n",
    "h = tf.keras.layers.Masking(mask_value=0.0)(h)\n",
    "_, h_state, c_state = tf.keras.layers.LSTM(512, return_state=True, return_sequences=True)(h)\n",
    "\n",
    "encoder = tf.keras.Model(inputs, [h_state, c_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:08.113702Z",
     "iopub.status.busy": "2022-06-29T06:49:08.113160Z",
     "iopub.status.idle": "2022-06-29T06:49:08.123831Z",
     "shell.execute_reply": "2022-06-29T06:49:08.121907Z",
     "shell.execute_reply.started": "2022-06-29T06:49:08.113657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 128)]         0         \n",
      "                                                                 \n",
      " embed_end_token_1 (EmbedEnd  (None, 14, 128)          128       \n",
      " Token)                                                          \n",
      "                                                                 \n",
      " masking (Masking)           (None, 14, 128)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 14, 512),         1312768   \n",
      "                              (None, 512),                       \n",
      "                              (None, 512)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,312,896\n",
      "Trainable params: 1,312,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:08.126538Z",
     "iopub.status.busy": "2022-06-29T06:49:08.125567Z",
     "iopub.status.idle": "2022-06-29T06:49:09.443255Z",
     "shell.execute_reply": "2022-06-29T06:49:09.441923Z",
     "shell.execute_reply.started": "2022-06-29T06:49:08.126489Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 512)\n",
      "(16, 512)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataset:\n",
    "    outputs = encoder(x)\n",
    "    break\n",
    "    \n",
    "print(outputs[0].shape)\n",
    "print(outputs[1].shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the decoder network\n",
    "The decoder network follows the schematic diagram below. \n",
    "\n",
    "![Decoder schematic](data/neural_translation_model_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:09.445765Z",
     "iopub.status.busy": "2022-06-29T06:49:09.445314Z",
     "iopub.status.idle": "2022-06-29T06:49:09.452756Z",
     "shell.execute_reply": "2022-06-29T06:49:09.451263Z",
     "shell.execute_reply.started": "2022-06-29T06:49:09.445722Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:09.455632Z",
     "iopub.status.busy": "2022-06-29T06:49:09.455053Z",
     "iopub.status.idle": "2022-06-29T06:49:09.469018Z",
     "shell.execute_reply": "2022-06-29T06:49:09.467684Z",
     "shell.execute_reply.started": "2022-06-29T06:49:09.455587Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.embedding = Embedding(vocab_size, 128, mask_zero=True)\n",
    "        self.lstm = LSTM(512, return_sequences=True, return_state=True)\n",
    "        self.dense = Dense(vocab_size) \n",
    "\n",
    "    def call(self, inputs, hidden_state=None, cell_state=None):\n",
    "        h = self.embedding(inputs)\n",
    "        h, hidden_state, cell_state = self.lstm(h, initial_state=[hidden_state, cell_state])\n",
    "        output = self.dense(h)\n",
    "        return output, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:09.472110Z",
     "iopub.status.busy": "2022-06-29T06:49:09.471508Z",
     "iopub.status.idle": "2022-06-29T06:49:09.490503Z",
     "shell.execute_reply": "2022-06-29T06:49:09.489256Z",
     "shell.execute_reply.started": "2022-06-29T06:49:09.471991Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:09.492202Z",
     "iopub.status.busy": "2022-06-29T06:49:09.491876Z",
     "iopub.status.idle": "2022-06-29T06:49:12.124965Z",
     "shell.execute_reply": "2022-06-29T06:49:12.123602Z",
     "shell.execute_reply.started": "2022-06-29T06:49:09.492158Z"
    }
   },
   "outputs": [],
   "source": [
    "for x,y in train_dataset.take(1):\n",
    "    enc_h_state, enc_c_state = encoder(x)\n",
    "    output, dec_h_state, dec_c_state = decoder(y, enc_h_state, enc_h_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:12.128537Z",
     "iopub.status.busy": "2022-06-29T06:49:12.126975Z",
     "iopub.status.idle": "2022-06-29T06:49:12.137535Z",
     "shell.execute_reply": "2022-06-29T06:49:12.136079Z",
     "shell.execute_reply.started": "2022-06-29T06:49:12.128489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 512)\n",
      "(16, 512)\n",
      "(16, 512)\n",
      "(16, 512)\n",
      "(16, 14, 5744)\n"
     ]
    }
   ],
   "source": [
    "print(enc_h_state.shape)\n",
    "print(enc_c_state.shape)\n",
    "print(dec_h_state.shape)\n",
    "print(dec_c_state.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:12.140798Z",
     "iopub.status.busy": "2022-06-29T06:49:12.140142Z",
     "iopub.status.idle": "2022-06-29T06:49:12.154457Z",
     "shell.execute_reply": "2022-06-29T06:49:12.152902Z",
     "shell.execute_reply.started": "2022-06-29T06:49:12.140753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  735232    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               multiple                  1312768   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  2946672   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,994,672\n",
      "Trainable params: 4,994,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make a custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:12.157431Z",
     "iopub.status.busy": "2022-06-29T06:49:12.157004Z",
     "iopub.status.idle": "2022-06-29T06:49:12.164682Z",
     "shell.execute_reply": "2022-06-29T06:49:12.163167Z",
     "shell.execute_reply.started": "2022-06-29T06:49:12.157400Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:12.167764Z",
     "iopub.status.busy": "2022-06-29T06:49:12.166473Z",
     "iopub.status.idle": "2022-06-29T06:49:12.175592Z",
     "shell.execute_reply": "2022-06-29T06:49:12.173951Z",
     "shell.execute_reply.started": "2022-06-29T06:49:12.167717Z"
    }
   },
   "outputs": [],
   "source": [
    "trainable_variables = encoder.trainable_variables + decoder.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:12.178456Z",
     "iopub.status.busy": "2022-06-29T06:49:12.177381Z",
     "iopub.status.idle": "2022-06-29T06:49:12.188025Z",
     "shell.execute_reply": "2022-06-29T06:49:12.186286Z",
     "shell.execute_reply.started": "2022-06-29T06:49:12.178406Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def optimization(eng_in, deu_in, deu_out):\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_h, enc_c = encoder(eng_in)\n",
    "        dec_out,_,_ = decoder(deu_in, enc_h, enc_c)\n",
    "        loss_val = tf.math.reduce_mean(loss(deu_out, dec_out))\n",
    "        gradients = tape.gradient(loss_val, trainable_variables)\n",
    "    return loss_val, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T06:49:12.191353Z",
     "iopub.status.busy": "2022-06-29T06:49:12.190524Z",
     "iopub.status.idle": "2022-06-29T07:04:16.205390Z",
     "shell.execute_reply": "2022-06-29T07:04:16.203910Z",
     "shell.execute_reply.started": "2022-06-29T06:49:12.191306Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss_avg = tf.keras.metrics.Mean()\n",
    "    val_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "    for eng, deu in train_dataset:\n",
    "        deu_in, deu_out = deu[:, :-1], deu[:, 1:]\n",
    "        loss_value, gradients = optimization(eng, deu_in, deu_out)\n",
    "        optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "        train_loss_avg(loss_value)\n",
    "\n",
    "    for eng, deu in test_dataset:\n",
    "        deu_in, deu_out = deu[:, :-1], deu[:, 1:]\n",
    "        loss_value, _ = optimization(eng, deu_in, deu_out)\n",
    "        val_loss_avg(loss_value)\n",
    "\n",
    "\n",
    "    train_loss.append(train_loss_avg.result())\n",
    "    val_loss.append(val_loss_avg.result())\n",
    "\n",
    "    print('Epoch {}, train loss {}, val loss {}'.format(epoch, train_loss[-1], val_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T07:23:19.945208Z",
     "iopub.status.busy": "2022-06-29T07:23:19.944517Z",
     "iopub.status.idle": "2022-06-29T07:23:20.162003Z",
     "shell.execute_reply": "2022-06-29T07:23:20.160413Z",
     "shell.execute_reply.started": "2022-06-29T07:23:19.945157Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss, label='Training')\n",
    "plt.plot(val_loss, label='Validation')\n",
    "plt.title('Epochs vs. Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use the model to translate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of illustration, we will import saved `encoder` and `decoder` models\n",
    "Note that this word2word NLP model is a computationally demanding one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_weights('nmt/encoder.h5')\n",
    "decoder.load_weights('nmt/decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T07:04:33.960401Z",
     "iopub.status.busy": "2022-06-29T07:04:33.959536Z",
     "iopub.status.idle": "2022-06-29T07:04:35.155749Z",
     "shell.execute_reply": "2022-06-29T07:04:35.154271Z",
     "shell.execute_reply.started": "2022-06-29T07:04:33.960351Z"
    }
   },
   "outputs": [],
   "source": [
    "eng = []\n",
    "deu = []\n",
    "for sente in data_examples:\n",
    "    en, de = re.split(\"\\t\", sente)[0:2]\n",
    "    eng.append(preprocess_sentence(en))\n",
    "    deu.append(preprocess_sentence(de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T07:04:35.165330Z",
     "iopub.status.busy": "2022-06-29T07:04:35.162077Z",
     "iopub.status.idle": "2022-06-29T07:04:35.175113Z",
     "shell.execute_reply": "2022-06-29T07:04:35.173621Z",
     "shell.execute_reply.started": "2022-06-29T07:04:35.165266Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(eng), size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T07:04:35.224889Z",
     "iopub.status.busy": "2022-06-29T07:04:35.223279Z",
     "iopub.status.idle": "2022-06-29T07:04:35.962633Z",
     "shell.execute_reply": "2022-06-29T07:04:35.961357Z",
     "shell.execute_reply.started": "2022-06-29T07:04:35.224844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: i see tom .\n",
      "Deutsch True: ich sehe tom .\n",
      "Deutsch Pred: ich sehe tom .\n",
      "\n",
      "English: there's no proof .\n",
      "Deutsch True: es gibt keine beweise .\n",
      "Deutsch Pred: es ist kein bisschen da .\n",
      "\n",
      "English: i'll go ask tom .\n",
      "Deutsch True: ich frage tom .\n",
      "Deutsch Pred: ich gucke fernsehen .\n",
      "\n",
      "English: are we going far ?\n",
      "Deutsch True: gehen wir weit weg ?\n",
      "Deutsch Pred: gehen wir weit weg ?\n",
      "\n",
      "English: tom sounded busy .\n",
      "Deutsch True: tom klang beschaeftigt .\n",
      "Deutsch Pred: tom wirkte stumm .\n",
      "\n",
      "English: did you hit tom ?\n",
      "Deutsch True: haben sie tom geschlagen ?\n",
      "Deutsch Pred: haben sie tom geschlagen ?\n",
      "\n",
      "English: i won't fail .\n",
      "Deutsch True: ich werde nicht versagen .\n",
      "Deutsch Pred: ich habe es nicht gemeint .\n",
      "\n",
      "English: he began running .\n",
      "Deutsch True: er fing an zu rennen .\n",
      "Deutsch Pred: er ist in tokyo gegangen .\n",
      "\n",
      "English: stay cool .\n",
      "Deutsch True: bleibt ruhig .\n",
      "Deutsch Pred: bleib duenn .\n",
      "\n",
      "English: did tom send you ?\n",
      "Deutsch True: hat tom dich geschickt ?\n",
      "Deutsch Pred: hat tom euch gekuesst ?\n",
      "\n",
      "English: what is it ?\n",
      "Deutsch True: was ist das fuer ein ding ?\n",
      "Deutsch Pred: was ist es alles ?\n",
      "\n",
      "English: are you mad ?\n",
      "Deutsch True: bist du sauer ?\n",
      "Deutsch Pred: bist du impulsiv ?\n",
      "\n",
      "English: he laughed .\n",
      "Deutsch True: er lachte .\n",
      "Deutsch Pred: er lenkte ein .\n",
      "\n",
      "English: i was happy then .\n",
      "Deutsch True: damals war ich gluecklich .\n",
      "Deutsch Pred: ich war zu dick .\n",
      "\n",
      "English: tom looks tired .\n",
      "Deutsch True: tom sieht muede aus .\n",
      "Deutsch Pred: tom sieht bleich aus .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_token = tokenizer.word_index['<start>']\n",
    "end_token = tokenizer.word_index['<end>']\n",
    "\n",
    "for i in np.random.choice(len(eng), size=15):\n",
    "    en = eng[i]\n",
    "    en = tf.strings.split(en)\n",
    "    en_em = embedding_layer(en)\n",
    "    padding = [[tf.math.maximum(13-tf.shape(en_em)[0],0), 0], [0,0]]\n",
    "    padded = tf.expand_dims(tf.pad(en_em, padding), axis = 0)\n",
    "    \n",
    "    curr_token = start_token\n",
    "    h_state, c_state = encoder(padded)\n",
    "    \n",
    "    deu_sente=[]\n",
    "    \n",
    "    while len(deu_sente) < 15:\n",
    "        inputs = tf.Variable([[curr_token]])\n",
    "        out, h_state, c_state = decoder(inputs, h_state, c_state)\n",
    "        curr_token = np.argmax(out[0][0].numpy())\n",
    "        if curr_token==end_token:\n",
    "            break\n",
    "        deu_word = tokenizer.index_word[curr_token]\n",
    "        deu_sente.append(deu_word)\n",
    "        \n",
    "    print(\"English: {}\".format(eng[i]))\n",
    "    print(\"Deutsch True: {}\".format(deu[i]))\n",
    "    print(\"Deutsch Pred: {}\".format(' '.join(deu_sente)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
